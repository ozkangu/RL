# Training Guide - BTC/USD RL Trading Bot

**Epic 3.3 (PBI-025): Ä°lk EÄŸitim Rehberi**

Bu dÃ¶kÃ¼man, BTC/USD RL trading botunun ilk eÄŸitimini Ã§alÄ±ÅŸtÄ±rmak iÃ§in gerekli adÄ±mlarÄ± iÃ§erir.

---

## ğŸ¯ Ã–n Gereksinimler

### 1. Veri HazÄ±rlÄ±ÄŸÄ±

BTC/USD 1-saatlik OHLCV verisini hazÄ±rlayÄ±n:

```csv
timestamp,open,high,low,close,volume
2023-01-01 00:00:00,30000.0,30100.0,29900.0,30050.0,1000000
2023-01-01 01:00:00,30050.0,30150.0,30000.0,30100.0,1100000
...
```

**Ã–nerilen Veri KaynaklarÄ±:**
- Binance API
- CoinGecko API
- Kraken API
- Historical data CSV'leri

**Minimum Veri MiktarÄ±:**
- En az 2000 saat (83 gÃ¼n) veri
- Ã–nerilen: 8000+ saat (333+ gÃ¼n)

Veriyi `data/btcusd_1h.csv` olarak kaydedin.

---

## ğŸš€ Ä°lk EÄŸitimi BaÅŸlatma

### AdÄ±m 1: Dependencies YÃ¼kleyin

```bash
pip install -r requirements.txt
```

### AdÄ±m 2: KonfigÃ¼rasyonlarÄ± DoÄŸrulayÄ±n

```bash
python config_validator.py
```

**Beklenen Ã‡Ä±ktÄ±:**
```
âœ“ All configurations are valid!
```

### AdÄ±m 3: Test Verisiyle Dry Run

KÃ¼Ã§Ã¼k bir test verisiyle sistemi test edin:

```bash
# Test data oluÅŸtur (Ã¶rnek)
python -c "
import pandas as pd
import numpy as np

n = 2000
dates = pd.date_range('2023-01-01', periods=n, freq='1H')
close = 30000 + np.cumsum(np.random.randn(n) * 100)
df = pd.DataFrame({
    'timestamp': dates,
    'open': close * 0.999,
    'high': close * 1.01,
    'low': close * 0.99,
    'close': close,
    'volume': np.random.lognormal(10, 1, n)
})
df.to_csv('data/btcusd_1h.csv', index=False)
print('Test data created!')
"
```

### AdÄ±m 4: EÄŸitimi BaÅŸlatÄ±n

```bash
python train.py \
  --training-config configs/training.yaml \
  --env-config configs/env.yaml \
  --features-config configs/features.yaml
```

---

## ğŸ“Š EÄŸitim Parametreleri

### VarsayÄ±lan Parametreler (MVP)

**Training:**
- Total timesteps: 200,000
- Checkpoint frequency: 10,000 steps
- Seed: 42

**PPO Hyperparameters:**
- Learning rate: 0.0003
- n_steps: 2048
- Batch size: 64
- Gamma: 0.99
- Entropy coefficient: 0.01

**Environment:**
- Window size: 24 bars
- Initial cash: $10,000
- Transaction cost: 0.1%
- Slippage: 0.05%

---

## ğŸ“ˆ EÄŸitim Ä°lerlemesini Ä°zleme

### TensorBoard ile Monitoring

```bash
tensorboard --logdir artifacts/tensorboard/
```

TarayÄ±cÄ±nÄ±zda aÃ§Ä±n: http://localhost:6006

**Ä°zlenecek Metrikler:**
- `rollout/ep_rew_mean`: Ortalama episode reward
- `rollout/ep_len_mean`: Ortalama episode uzunluÄŸu
- `train/policy_loss`: Policy loss
- `train/value_loss`: Value function loss
- `train/entropy_loss`: Entropy loss

### Console Output

Training sÄ±rasÄ±nda gÃ¶recekleriniz:

```
======================================================================
BTC/USD RL TRADING AGENT TRAINING
======================================================================

[1/7] Loading and validating configurations...
âœ“ Environment config validation passed
âœ“ Training config validation passed
âœ“ Features config validation passed

[2/7] Preparing data...
Data split:
  Total samples: 1974
  Train: 1184 samples (60.0%)
  Val:   395 samples (20.0%)
  Test:  395 samples (20.0%)

[3/7] Creating training environment...
Using DummyVecEnv with 1 environment

[4/7] Initializing PPO agent...
PPO agent initialized with hyperparameters:
  Learning rate: 0.0003
  n_steps: 2048
  batch_size: 64
  gamma: 0.99
  ent_coef: 0.01

[5/7] Setting up callbacks...
Checkpoints will be saved to: ckpts/
Save frequency: every 10000 steps

[6/7] Starting training...
======================================================================
Training for 200,000 timesteps...

---------------------------------
| rollout/           |          |
|    ep_len_mean     | 150      |
|    ep_rew_mean     | 0.023    |
| time/              |          |
|    fps             | 245      |
|    iterations      | 10       |
|    time_elapsed    | 83       |
|    total_timesteps | 20480    |
| train/             |          |
|    entropy_loss    | -0.98    |
|    policy_loss     | -0.012   |
|    value_loss      | 0.045    |
---------------------------------
```

---

## ğŸ¯ Ä°lk EÄŸitim BaÅŸarÄ± Kriterleri

### Episode Reward ArtÄ±ÅŸÄ±

- **BaÅŸlangÄ±Ã§**: ~0 (rastgele policy)
- **Ä°lk 50k steps**: Pozitif reward'a ulaÅŸmalÄ±
- **100k steps**: KararlÄ± Ã¶ÄŸrenme gÃ¶rÃ¼lmeli
- **200k steps**: Buy & Hold'dan daha iyi performans (hedef)

### Convergence Kontrolleri

âœ… **Ä°yi Ä°ÅŸaretler:**
- Ortalama reward artÄ±yor
- Episode length stabil
- Value loss azalÄ±yor
- Policy loss stabil

âš ï¸ **Sorunlu Ä°ÅŸaretler:**
- Reward sÃ¼rekli dÃ¼ÅŸÃ¼yor
- Episode length Ã§ok kÄ±sa (erken termination)
- Value loss exploding
- NaN values

---

## ğŸ”§ Sorun Giderme

### Problem: "FileNotFoundError: data/btcusd_1h.csv"

**Ã‡Ã¶zÃ¼m:** Veri dosyasÄ±nÄ± doÄŸru yere koyduÄŸunuzdan emin olun.

```bash
ls -la data/btcusd_1h.csv
```

### Problem: "ValueError: DataFrame must have at least X rows"

**Ã‡Ã¶zÃ¼m:** Daha fazla veri ekleyin. Minimum 2000 satÄ±r gerekli.

### Problem: Training Ã§ok yavaÅŸ

**Ã‡Ã¶zÃ¼m 1:** GPU kullanÄ±n (PyTorch CUDA)
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

**Ã‡Ã¶zÃ¼m 2:** `total_timesteps` azaltÄ±n (test iÃ§in)
```yaml
# configs/training.yaml
training:
  total_timesteps: 50000  # 200000 yerine
```

### Problem: Agent Ã¶ÄŸrenmiyor

**Kontroller:**
1. **Reward signal:** Ã‡ok kÃ¼Ã§Ã¼k veya Ã§ok bÃ¼yÃ¼k mÃ¼?
2. **Learning rate:** Ã‡ok yÃ¼ksek (divergence) veya Ã§ok dÃ¼ÅŸÃ¼k (yavaÅŸ)?
3. **Environment:** Episode'lar Ã§ok kÄ±sa mÄ±?

**Ã‡Ã¶zÃ¼mler:**
- Entropy coefficient artÄ±r: `ent_coef: 0.01 â†’ 0.05`
- Learning rate ayarla: `learning_rate: 0.0001 veya 0.001`
- Max steps artÄ±r: `max_steps: 500 â†’ 1000`

---

## ğŸ“ EÄŸitim Ã‡Ä±ktÄ±larÄ±

### Checkpoint'ler

```
ckpts/
â”œâ”€â”€ rl_model_10000_steps.zip
â”œâ”€â”€ rl_model_20000_steps.zip
â”œâ”€â”€ ...
â”œâ”€â”€ rl_model_200000_steps.zip
â”œâ”€â”€ final_model.zip
â””â”€â”€ best_model/
    â””â”€â”€ best_model.zip  # En iyi validation performance
```

### TensorBoard LoglarÄ±

```
artifacts/tensorboard/
â””â”€â”€ PPO_1/
    â””â”€â”€ events.out.tfevents...
```

### Evaluation Logs

```
ckpts/eval_logs/
â””â”€â”€ evaluations.npz
```

---

## ğŸ“ Ä°lk EÄŸitim SonrasÄ±

### 1. Best Model'i DeÄŸerlendirin

```bash
python evaluate.py \
  --model ckpts/best_model/best_model.zip \
  --config configs/env.yaml
```

### 2. TensorBoard'da Analiz Edin

Ã–nemli sorular:
- Agent convergence gÃ¶sterdi mi?
- Validation performance training'e benzer mi (overfitting yok)?
- Buy & Hold'dan daha iyi mi?

### 3. Hyperparameter Tuning

Ä°lk sonuÃ§lara gÃ¶re ayarlamalar:
- Learning rate
- Entropy coefficient
- Network architecture (sonraki iterasyon)

### 4. Daha Uzun Training

Ä°lk eÄŸitim baÅŸarÄ±lÄ±ysa:
```yaml
training:
  total_timesteps: 500000  # veya 1M
```

---

## ğŸ“‹ Checklist

Ä°lk eÄŸitim Ã¶ncesi:
- [ ] Data hazÄ±rlandÄ± ve `data/btcusd_1h.csv` konumunda
- [ ] Config'ler validate edildi
- [ ] Dependencies yÃ¼klendi
- [ ] `ckpts/` ve `artifacts/` klasÃ¶rleri oluÅŸturuldu

EÄŸitim sÄ±rasÄ±nda:
- [ ] TensorBoard aÃ§Ä±k ve monitoring yapÄ±lÄ±yor
- [ ] Console output dÃ¼zenli gÃ¶zlemleniyor
- [ ] Checkpoint'ler kaydediliyor

EÄŸitim sonrasÄ±:
- [ ] Training tamamlandÄ± (hatasÄ±z)
- [ ] Best model kaydedildi
- [ ] TensorBoard loglarÄ± mevcut
- [ ] Ä°lk evaluation yapÄ±ldÄ±

---

## ğŸ¯ Sonraki AdÄ±mlar

BaÅŸarÄ±lÄ± bir ilk eÄŸitimden sonra:

1. **Faz 4: Evaluation & Backtest**
   - Comprehensive metrics
   - Benchmark karÅŸÄ±laÅŸtÄ±rmalarÄ±
   - Visualization

2. **Hyperparameter Optimization**
   - Grid search
   - Optuna

3. **Advanced Features**
   - T+1 execution
   - Continuous action space
   - Regime detection

4. **Paper Trading**
   - Real-time testing
   - Risk management

---

## ğŸ“ YardÄ±m

Sorun yaÅŸarsanÄ±z:
1. Log dosyalarÄ±nÄ± kontrol edin
2. Config validation Ã§alÄ±ÅŸtÄ±rÄ±n
3. Test suite'i Ã§alÄ±ÅŸtÄ±rÄ±n: `pytest -v`

**Training sÃ¼resi (tahmini):**
- CPU: ~2-4 saat (200k timesteps)
- GPU: ~30-60 dakika (200k timesteps)

---

**Good luck with your first training! ğŸš€**
